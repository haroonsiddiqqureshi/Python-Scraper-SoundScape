from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from urllib.parse import urljoin

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå artist.py (‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå artist.py ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
from tester import get_page_destination_data, save_artist

def get_all_category_links(listing_url):
    links = []
    
    edge_options = Options()
    edge_options.add_argument("--log-level=3") 
    edge_options.add_experimental_option('excludeSwitches', ['enable-logging'])
    edge_options.add_argument("--headless")
    edge_options.add_argument("--window-size=1920,1080")
    
    DRIVER_PATH = "msedgedriver.exe" 
    service = Service(executable_path=DRIVER_PATH)
    driver = webdriver.Edge(service=service, options=edge_options)

    try:
        print(f"üåç Accessing listing page: {listing_url}")
        driver.get(listing_url)

        print("‚è≥ Scrolling to load content...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
        
        print("‚úÖ Scroll finished. Extracting links...")

        # ==================================================================================
        # ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ <a> ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô div.CateArtist
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á HTML: <a href="/th/artists/193" ...>
        # ==================================================================================
        
        target_selector = "div.CateArtist a"
        
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, target_selector))
        )
        
        a_elements = driver.find_elements(By.CSS_SELECTOR, target_selector)
        print(f"   Found {len(a_elements)} potential category links.")

        for a in a_elements:
            try:
                href = a.get_attribute("href")
                title = a.get_attribute("title") # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå‡∏î‡πâ‡∏ß‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô "‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡πÑ‡∏ó‡∏¢ ‡∏ä‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß")
                
                # ‡∏Å‡∏£‡∏≠‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå: ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ /artist/ ‡∏´‡∏£‡∏∑‡∏≠ /artists/
                if href and ("artist" in href):
                    full_url = urljoin(listing_url, href)
                    
                    if full_url not in links:
                        links.append(full_url)
                        # print(f"      + Found Category: {title} -> {full_url}")
                        
            except Exception:
                continue
        # ==================================================================================

    except Exception as e:
        print(f"‚ùå Error getting links: {e}")
    finally:
        driver.quit()
    
    return links

if __name__ == "__main__":
    # URL ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô
    MAIN_PAGE_URL = "https://www.joox.com/th/artists" 

    print("üöÄ Starting Category Scraper...")
    
    # 1. ‡πÑ‡∏õ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (‡πÄ‡∏ä‡πà‡∏ô ‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡πÑ‡∏ó‡∏¢‡∏ä‡∏≤‡∏¢, ‡∏´‡∏ç‡∏¥‡∏á)
    category_urls = get_all_category_links(MAIN_PAGE_URL)
    
    print(f"\nüìÇ Found {len(category_urls)} categories to process.")
    print("-" * 50)

    # 2. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏à‡∏≤‡∏∞‡∏î‡∏π‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
    for i, url in enumerate(category_urls):
        print(f"\n[{i+1}/{len(category_urls)}] Processing Category: {url}")
        
        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏° (artist.py) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ô‡∏±‡πâ‡∏ô‡πÜ
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° timeout ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞
            artist_data = get_page_destination_data(url, headless=True, timeout=30)
            
            if artist_data:
                print(f"   ‚úÖ Extracted {len(artist_data)} artists from this category.")
                for item in artist_data:
                    save_artist(item)
            else:
                print("   ‚ö†Ô∏è No artists found in this category.")
                
        except Exception as e:
            print(f"   ‚ùå Failed to process {url}: {e}")

    print("\nüéâ All Done!")