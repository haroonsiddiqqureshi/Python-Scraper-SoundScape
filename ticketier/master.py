from selenium import webdriver
from selenium.webdriver.edge.service import Service
from selenium.webdriver.edge.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
from urllib.parse import urljoin

from tester import get_page_destination_data, save_concert

def get_all_concert_links(listing_url):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤ '‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ï' ‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Next.js ‡πÅ‡∏•‡∏∞ HTML ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà)
    """
    links = []
    
    edge_options = Options()
    edge_options.add_argument("--headless=new")  # ‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î‡πÉ‡∏´‡∏°‡πà
    edge_options.add_argument("--window-size=1920,1080")
    
    # ‡∏õ‡∏•‡∏≠‡∏° User-Agent (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å)
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
    edge_options.add_argument(f'user-agent={user_agent}')
    
    # ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Bot
    edge_options.add_argument("--disable-blink-features=AutomationControlled")
    edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    edge_options.add_experimental_option('useAutomationExtension', False)
    edge_options.add_argument("--log-level=3")
    
    DRIVER_PATH = "msedgedriver.exe" 
    service = Service(executable_path=DRIVER_PATH)
    driver = webdriver.Edge(service=service, options=edge_options)

    try:
        print(f"üåç Accessing listing page: {listing_url}")
        driver.get(listing_url)

        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î: ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏≠ tag <a> ‡∏ó‡∏µ‡πà‡∏°‡∏µ href ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ /events/
        print("‚è≥ Waiting for content to load...")
        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "a[href^='/events/']"))
            )
        except Exception:
            print("‚ö†Ô∏è Warning: Initial wait timed out (Web might be slow).")

        # Auto-Scroll
        print("‚è≥ Scrolling...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2.5) # ‡∏û‡∏±‡∏Å‡∏ô‡∏≤‡∏ô‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡πÉ‡∏´‡πâ Next.js render ‡∏Ç‡∏≠‡∏á
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        print("üîç Extracting links...")

        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 ‡∏´‡∏≤ <a> ‡∏ó‡∏µ‡πà href ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ /events/
        elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/events/']")
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2 (‡πÅ‡∏ú‡∏ô‡∏™‡∏≥‡∏£‡∏≠‡∏á): ‡∏ñ‡πâ‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏£‡∏Å‡πÑ‡∏î‡πâ‡∏ô‡πâ‡∏≠‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Javascript ‡∏î‡∏∂‡∏á
        if len(elements) == 0:
            print("‚ö†Ô∏è Selenium found 0 elements, trying JavaScript injection...")
            # ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå JS ‡∏î‡∏∂‡∏á‡∏ó‡∏∏‡∏Å Link ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ /events/
            js_links = driver.execute_script("""
                var links = [];
                var elements = document.querySelectorAll("a[href*='/events/']");
                elements.forEach(e => links.push(e.href));
                return links;
            """)
            
            for raw_link in js_links:
                if "/events/" in raw_link and "login" not in raw_link:
                     # JS ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Relative path ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ
                    full_url = urljoin(listing_url, raw_link)
                    if full_url not in links:
                        links.append(full_url)
        else:
            # Loop ‡∏õ‡∏Å‡∏ï‡∏¥‡∏à‡∏≤‡∏Å Selenium Elements
            for a in elements:
                try:
                    href = a.get_attribute("href")
                    if href and "/events/" in href and "login" not in href:
                        full_url = urljoin(listing_url, href)
                        if full_url not in links:
                            links.append(full_url)
                except:
                    continue

    except Exception as e:
        print(f"‚ùå Error getting links: {e}")
    finally:
        driver.quit()
    
    return links

def trigger_cleanup(origin_name):
    url = "http://127.0.0.1:8000/api/concerts/cleanup"
    try:
        # ‡∏™‡πà‡∏á origin ‡πÑ‡∏õ‡∏ö‡∏≠‡∏Å backend ‡∏ß‡πà‡∏≤‡πÄ‡∏à‡πâ‡∏≤‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πÅ‡∏Å‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
        res = requests.post(url, json={"origin": origin_name}, timeout=10)
        print(f"\nüßπ Cleanup Status ({origin_name}): {res.status_code}")
        print(f"   Deleted (Soft): {res.json().get('deleted_count', 0)} items")
    except Exception as e:
        print(f"   ‚ùå Cleanup Failed: {e}")

if __name__ == "__main__":
    # ‡∏´‡∏ô‡πâ‡∏≤ Ticketier
    MAIN_PAGE_URL = "https://www.ticketier.com/events"
    ORIGIN_NAME = "Ticketier"

    print("üöÄ Starting Ticketier Master Scraper...")
    
    # 1. ‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    concert_urls = get_all_concert_links(MAIN_PAGE_URL)
    
    print(f"\nüìÇ Total unique concerts found: {len(concert_urls)}")
    print("-" * 50)

    # 2. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå
    for i, url in enumerate(concert_urls):
        print(f"\n[{i+1}/{len(concert_urls)}] Processing: {url}")
        
        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏≤‡∏Å ticketier.py
            concert_data = get_page_destination_data(url, headless=True, timeout=20)
            
            if concert_data:
                print(f"   ‚úÖ Name: {concert_data.get('name')}")
                save_concert(concert_data) # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            else:
                print("   ‚ö†Ô∏è Data extraction failed or empty.")
                
        except Exception as e:
            print(f"   ‚ùå Failed to process {url}: {e}")
        pass

    print("\n------------------------------------------------")
    print("üßπ Starting Cleanup process for missing concerts...")
    trigger_cleanup(ORIGIN_NAME)
    print("------------------------------------------------")

    print("\nüéâ All Done!")